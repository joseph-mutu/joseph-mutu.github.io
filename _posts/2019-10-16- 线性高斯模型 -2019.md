---
layout:     post   				    # 使用的布局（不需要改）
title:      Linear Gaussian Model				# 标题 
subtitle:   Bayesian Linear regression,multivariable gaussian           #副标题
date:       2019-10-16 				# 时间
author:     WYX 						# 作者
header-img: img/wuxia11.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - Bayesian Inference

---

---

# 线性高斯模型

假设存在数据 


$$
Data = \lbrace (x_1,y_1),(x_2,y_2)\ldots (x_N,y_N \rbrace \\
\space \\
x \in \mathbb{R}^P, y \in \mathbb{R} \\
\space \\
X = (x_1 ~  x_2 ~ \ldots ~ x_N )^T
$$


向量默认为`列向量`，则 $x$ 可以表示为矩阵的形式


$$
\left(
\begin{matrix}
x_{11} & x_{12} & x_{13} &\ldots & x_{1P} \\
x_{21} & x_{22} & x_{23} &\ldots & x_{2P} \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
x_{N1} & x_{N2} & x_{N3} &\ldots & x_{NP}
\end{matrix}
\right)_{N \times P}
$$


设数据独立同分布，且服从于均值 $\mu$ 协方差矩阵为 $\Sigma$ 的高斯分布


$$
x_i \sim^{iid} N(\mu,\Sigma) \\
\space \\
\mu: P \times 1 ; \Sigma: P \times P \\
\space \\
\theta = (\mu ~\Sigma)
$$
其中多维高斯分布的公式如下：


$$
X \sim N(\mu,\Sigma) = \frac{1}{2\pi^{\frac{P}{2}} |\Sigma|^{\frac{1}{2}}} ~ exp \lbrace -\frac{1}{2}(x-\mu)^T \Sigma^{-1} (x-\mu) \rbrace
$$

### 重要定理

已知 $X$ 服从多维正态高斯分布 $N(\mu,\Sigma)$ ，若存在 $Y = AX + B$，则其期望与方差可以直接计算得出


$$
X \sim N(\mu,\Sigma) \\
\space \\

Y = AX +B \\
\space \\
\Rightarrow Y \sim N(A\mu + B,A\Sigma A^T)
$$


### 已知总体分布求边缘概率分布以及条件概率分布

已知数据 $x$ 服从多维高斯分布，则可以将 $x$ 其维度分为两块，如下


$$
x  = 
\left(
\begin{matrix}
x_a \\
x_b
\end{matrix}
\right),其中 x_a = m,x_b = n,m+n = P \\
\space \\
\mu  = 
\left(
\begin{matrix}
\mu_a \\
\mu_b
\end{matrix}
\right),
\Sigma  = 
\left(
\begin{matrix}
\Sigma_{aa} &\Sigma_{ab} \\
\Sigma_{ba} & \Sigma_{bb}
\end{matrix}
\right)
$$
则问题可以分为

- 求解 $p(x_a)$
- 求解 $p(x_b|x_a)$

#### 求$P(x_a)$

因为将 $x$ 分为两块，则可以将 $x_a$ 写为如下形式


$$
x_a = \underbrace{(I_m ~ 0)}_{A}\left( \begin{matrix}
x_a \\
x_b
\end{matrix}
\right)
$$


则根据定理可以写出 $x_a$ 的期望以及方差
$$
E[x_a] = (I_m ~ 0)\left( \begin{matrix}\mu_a \\\mu_b\end{matrix}\right) + 0 \\
= \mu_a \\
\space \\
Var[x_a] = A \Sigma A^T =  (I_m ~ 0)\left( \begin{matrix}\Sigma_{aa} & \Sigma_{ab} \\\Sigma_{ba} & \Sigma_{bb}\end{matrix}\right)\left( \begin{matrix}I_m \\ 0\end{matrix}\right) = \Sigma_{aa}
$$


#### 求 $P(x_b|x_a)$

条件概率的求解依据`构造性证明` ，上述条件概率的解释就是，给定 $x_a$ 的情况下，$x_b$ 的概率

先构造出新变量 $x_{b\cdot a}$ 如下


$$
x_{b\cdot a} = x_b - \Sigma_{ba}\Sigma_{aa}^{-1}x_a \\
\space \\
~~~结论： \\
\mu_{b\cdot a} = \mu_b-\mu_a \Sigma_{ba}\Sigma_{aa}^{-1} \\
\space \\
\Sigma_{bb\cdot a} = \Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}
$$


对 $x_{b\cdot a}$ 重写如下
$$
x_{b\cdot a} = \underbrace{(-\Sigma_{ba}\Sigma_{aa}^{-1} ~~~I_n)}_{A}\left( \begin{matrix}x_a \\ x_b\end{matrix}\right)
$$


则可以写出 $x_{b\cdot a} $ 的期望


$$
E[x_{b\cdot a} ] = (-\Sigma_{ba}\Sigma_{aa}^{-1} ~~~I_n) \left( \begin{matrix}\mu_a \\ \mu_b\end{matrix}\right) = \mu_b-\mu_a \Sigma_{ba}\Sigma_{aa}^{-1}
$$
方差如下，注意其中 $\Sigma_{aa}$ 为对称矩阵，所以其转置等于自身


$$
Var[x_{b\cdot a}] = A \Sigma A^T = (-\Sigma_{ba}\Sigma_{aa}^{-1} ~~~I_n) \left( \begin{matrix}\Sigma_{aa} & \Sigma_{ab} \\\Sigma_{ba} & \Sigma_{bb}\end{matrix}\right) \left( \begin{matrix}-\Sigma_{aa}^{-1}\Sigma_{ba}^T\\ I_n\end{matrix}\right)\\
= \left( \begin{matrix}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{aa} + \Sigma_{ba}\\ -\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab} + \Sigma_{bb}\end{matrix}\right)\left( \begin{matrix}-\Sigma_{aa}^{-1}\Sigma_{ba}^T\\ I_n\end{matrix}\right) \\
= \left( \begin{matrix}0\\ \Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}\end{matrix}\right)\left( \begin{matrix}-\Sigma_{aa}^{-1}\Sigma_{ba}^T\\ I_n\end{matrix}\right) \\
\space \\
= \Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}
$$


由此，可知 $x_{b\cdot a}$ 服从一个多元高斯分布，如下


$$
x_{b\cdot a} \sim N(\mu_{b \cdot a},\Sigma_{bb\cdot a})
$$


根据 $x_{b\cdot a}$，可以推出 $x_b$ 与 $x_a$ 之间存在关系式如下


$$
x_{b\cdot a} = x_b - \Sigma_{ba}\Sigma_{aa}^{-1}x_a  \\
\space \\
\Rightarrow  x_b = x_{b\cdot a}- \underbrace{\Sigma_{ba}\Sigma_{aa}^{-1}x_a}_{Constant}， 在求 p(x_b|x_a) 中，x_a 已经给定
$$


将上式 $x_b$ 与 $x_a$ 的关系式带入定理，可得


$$
E[x_b|x_a] = \underbrace{A}_{I} E[x_{b\cdot a}] + B = \mu_{b\cdot a}+ \Sigma_{ba}\Sigma_{aa}^{-1}x_a \\
\space \\
Var[x_b|x_a] = \Sigma_{bb\cdot a}
$$



### 给定边缘概率分布，求联合概率分布

给定 $x$ 以及 $y$ 的分布，且 $y$ 与 $x$ 存在以下线性关系，求 $p(y)$ 以及 p(x\|y)


$$
x = N(\mu,\Lambda^{-1}) \\
y = N(Ax+b,L^{-1}) \\
$$
先假设 $y$ 与 $x$ 之间存在噪声 $\epsilon$ ，且存在以下关系


$$
y = Ax + b + \epsilon \\
\space\\
where~ \epsilon \sim N(0,L^{-1})
$$
求 $y$ 的分布，以及 p(y\|x)​

#### $p(y)$ 的分布

对 $y$ 的期望进行分解如下



$$
E[y] = E[Ax + b + \epsilon] = \underbrace{E[Ax + b]}_{(1)} + \underbrace{E[\epsilon]}_{(2)} \\
\space \\
E[(1)] = A \mu + b; E[\epsilon] = 0 \\
\Rightarrow E[y] = A\mu+b
$$



其方差为
$$
Var[y] = Var[Ax + b +\epsilon] = \underbrace{Var[Ax + b]}_{定理} + Var[\epsilon] \\
\space \\
= A\Lambda^{-1}A^T + L^{-1}
$$


则 $y$ 服从如下正态分布
$$
y \sim N(A\mu + b, L^{-1} + A\Lambda^{-1}A^T)
$$


#### 求联合概率分布

如果能求得 $P(x,y)$ ，则根据之前的公式，则可以写出 p(y\|x) 将 $x,y$ 的联合概率分布写为两部分如下


$$
z  = 
\left(
\begin{matrix}
x \\
y
\end{matrix}
\right) \sim N(
\left[
\begin{matrix}
\mu_a \\
\mu_b
\end{matrix}
\right],
\Sigma  = 
\left(
\begin{matrix}
Var[x] = \Lambda^{-1} & ? \\
? & Var[y]= L^{-1} + A\Lambda^{-1}A^T 
\end{matrix}
\right)
$$


欠缺的地方为未知量，也就是 $x$ 与 $y$ 的协方差，算出协方差则可写出 p(y\|x) 
$$
Cov(x,y) = E[(x-E(x))(y-E(y))^T] \\
= E[(x - \mu) (y -A\mu +b)^T]\\
\space 将 y 与  x 的线性关系带入\\
= E[(x - \mu)(Ax + b + \epsilon - A\mu - b )^T] \\
= E[(x - \mu)(Ax+ \epsilon - A\mu)^T]\\
= E[(x-\mu)(Ax - A\mu)^T+ (x-\mu)\epsilon^T] \\
= E[(x-\mu)(Ax - A\mu)^T] + \underbrace{E[(x-\mu)\epsilon^T]}_{(1)}\\
$$

---

现对 (1) 式提出进行分析，因为 $x$ 与 $\epsilon$ 独立，则 $x-\mu$ 同样与 $\epsilon$ 独立，则(1) 可以写为


$$
E[(x-\mu)\epsilon^T] = E[(x-\mu)]\underbrace{E[\epsilon]}_{0} =0 
$$

---

则可以消去 (1) 式，
$$
Cov(x,y) = E[(x-\mu)(Ax - A\mu)^T] \\
=E[(x-\mu)(A(x-\mu))^T] \\
= E[(x-\mu)(x-\mu)^TA^T] \\
= \underbrace{E[(x-\mu)(x-\mu)^T]}_{x 的方差}A^T \\
= \Lambda^{-1} A^T
$$


则可以写出联合概率的分布为
$$
P(x,y) \sim N(
\left[
\begin{matrix}
\mu_a \\
\mu_b
\end{matrix}
\right],
\Sigma  = 
\left(
\begin{matrix}
Var[x] = \Lambda^{-1} & \Lambda^{-1} A^T \\
 A \Lambda^{-T} & Var[y]= L^{-1} + A\Lambda^{-1}A^T 
\end{matrix}
\right)
$$




## 贝叶斯线性回归

在贝叶斯线性回归当中，已知为数据


$$
Data = \lbrace (x_1,y_1),(x_2,y_2)\ldots (x_N,y_N \rbrace \\
\space \\
x \in \mathbb{R}^P, y \in \mathbb{R} \\
\space \\
X = (x_1 ~  x_2 ~ \ldots ~ x_N )^T = \left(
\begin{matrix}
x_{11} & x_{12} & x_{13} &\ldots & x_{1P} \\
x_{21} & x_{22} & x_{23} &\ldots & x_{2P} \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
x_{N1} & x_{N2} & x_{N3} &\ldots & x_{NP}
\end{matrix}
\right)_{N \times P} \\
\space \\
$$
其中 `label` y 与 x 之间存在如下关系


$$
\left\{ \begin{aligned} f(x) = w^Tx \\ y = f(x) + \epsilon   \end{aligned} \right. \\
\space \\
\epsilon \sim N(0,\delta^2)
$$


上述 $\epsilon$ 为噪声，在模型中假设噪声服从一个方差已知的正态分布，其方差为 $\delta^2$ 

贝叶斯线性回归目标分为 `Inference` 以及 `Prediction`



### Inference

Inference 意在求取后验分布，p(w\|Data)，根据贝叶斯公式，可以将 p(w\|Data) 分解为


$$
p(w|Data) = p(w|X,Y) = \frac{p(w,Y|X)}{p(Y|X)} = \frac{p(Y|X,w)p(w|X)}{p(Y|X)}
$$


因为 $w$ 与 $X$ 独立，则


$$
p(w|Data) \propto \underbrace{p(Y|X,w)}_{Likelihood}\underbrace{p(w)}_{prior}
$$
在模型中，同样假设参数 $w$  服从一个正态分布，且参数给定，如下


$$
w \sim N(0,\Sigma_p) \\
\space \\
p(Y|X,w) \sim N(w^Tx,\delta^2)
$$
 

则似然服从正态分布，且先验服从正态分布，根据正态分布自身的共轭性，可得其后验同样服从一个正态分布，但是参数未知，即


$$
p(W|Data) \sim N(\mu_w,\Sigma_w)
$$


#### 根据配方法求解参数

##### Likelihood

$$
p(Y|w,X) = \prod _{i=1}^N p(y_i|w,x_i) \\
= \frac{1}{2\pi^{\frac{N}{2}}\delta^N} exp \lbrace -\frac{1}{2\delta^2} \underbrace{\sum _{i=1}^N (y_i - w^Tx_i)^2}_{矩阵化} \rbrace \\
= \frac{1}{2\pi^{\frac{N}{2}}\delta^N} exp \lbrace -\frac{1}{2\delta^2} (Y^T-w^TX^T)(Y-XW) \rbrace \\
= \frac{1}{2\pi^{\frac{N}{2}}\delta^N} exp \lbrace -\frac{1}{2\delta^2} (Y-Xw)^T(Y-XW) \rbrace \\
=\frac{1}{2\pi^{\frac{N}{2}}\delta^N} exp \lbrace -\frac{1}{2} (Y-Xw)^T\underbrace{\delta^{-2} I_N}_{方差}(Y-XW) \rbrace
$$

上述将性质变换为了多元高斯的形式，则根据配方法，可以直接找出其方差和期望

---

矩阵维度的说明：
$$
Y-wX = N\times 1 - (N\times P)(P \times 1) = N \times 1 \\
(Y-wX)^T = 1 \times N\\
\delta^{-2}\cdot I_{N} = N \times N ,对角矩阵，对角元素全为 \delta^{-2} \\
则(Y-wX)^T\delta^{-2}I_{N} = 1 \times N
$$


---

根据上述可得，似然函数的期望以及方差为


$$
p(Y|w,X) \sim N(Xw,\delta^{-2}I)
$$
则后验分布可以重写为下式，因为正态分布的参数存在于 exp 的部分，exp 之前的部分为常数，所以下式只取正态分布的 exp 部分


$$
p(w|Data) \propto N(Xw,\delta^{-2}I) N(0,\Sigma_p) \\
\propto exp \lbrace \frac{1}{2}(Y-Xw)^T \delta^{-2}I(Y-Xw) \rbrace exp \lbrace -\frac{1}{2}w^T \Sigma_p^{-1}w \rbrace \\
=  exp \lbrace  \frac{1}{2\delta^2} (Y^T - w^TX^T)(Y-Xw)  -\frac{1}{2}w^T \Sigma_p^{-1}w \rbrace
$$

---

**Note**:如何用配方法寻找参数，在一般形式的多维高斯分布中，其公式如下
$$
N(\mu,\Sigma) = \frac{1}{(2\pi)^{\frac{P}{2}} |\Sigma|^2} exp \lbrace-\frac{1}{2} (X-\mu)^T \Sigma^{-1}(X-\mu) \rbrace \\
对指数部分进行展开 \\
=  exp \lbrace -\frac{1}{2} (X^T\Sigma^{-1} - \mu^T\Sigma^{-1})(X-\mu) \\
= exp \lbrace -\frac{1}{2}  (X^T\Sigma^{-1}X - \underbrace{X^T\Sigma^{-1}\mu}_{标量} -  \underbrace{\mu^T\Sigma^{-1}X}_{标量} + Constant) \\
=  exp \lbrace -\frac{1}{2}  (X^T\Sigma^{-1}X - 2\mu^T\Sigma^{-1}X + Constant)
$$


则可以看到，$\Sigma$ 部分位于其二次项位置，而 $\mu$ 位于一次项

---

则继续对后验进行分解，使用配方法寻找参数


$$
exp \lbrace  -\frac{1}{2\delta^2} (Y^T - w^TX^T)(Y-Xw)  -\frac{1}{2}w^T \Sigma_p^{-1}w \rbrace \\
= exp \lbrace-\frac{1}{2\delta^2} (Y^TY - \underbrace{Y^TXw}_{标量} - \underbrace{w^TX^TY}_{标量} + w^TX^TXw)  -\frac{1}{2}w^T \Sigma_p^{-1}w \rbrace\\
=  exp \lbrace-\frac{1}{2\delta^2} (Y^TY -2Y^TXw+ w^TX^TXw) - \frac{1}{2}w^T \Sigma_p^{-1}w \rbrace
$$
首先提取关于 w 的二次项
$$
二次项： -\frac{1}{2\delta^2}w^TX^TXw - \frac{1}{2}w^T \Sigma_p^{-1}w \\
= -\frac{1}{2}w^T\underbrace{(\delta^{-2}X^TX + \Sigma_p^{-1})}_{方差 ： A^{-1}}w
$$
提取关于 w 的一次项


$$
一次项:  -\frac{1}{2\delta^2} -2 Y^TXw \\
= \delta^{-2} Y^TXw\\
\Rightarrow  \delta^{-2} Y^TX = \mu^T A (配方)\\
\Rightarrow  A\mu = \delta^{-2}X^TY : A 为精度矩阵（协方差矩阵的逆，转置等于自身）\\
\Rightarrow  \mu = \delta^{-2} A^{-1}X^TY
$$
至此，后验部分求解完成，即


$$
P(w|Data) \sim N(\delta^{-2} A^{-1}X^TY,A^{-1})
$$


#### 预测 Prediction

预测是给定一个新的数据 $x^*$ ，计算新的 $y^*$，回忆模型如下


$$
Model:\\
\left\{
\begin{aligned}
f(x) &= w^Tx = x^Tw \\
y &= f(x) + \epsilon
\end{aligned}
\right. \\
\epsilon \sim N(0,\delta^2)
$$


##### 计算$f(x^*)$

$$
f(x^*) = x^*\underbrace{w}_{p(w)} \\
\space \\
p(w) \sim N(\mu_w,\Sigma_w) \\
\space \\
\mu_w = \delta^{-2} A^{-1}X^TY \\
\space \\
\Sigma_w = A^{-1} =\delta^{-2}X^TX + \Sigma_p^{-1}
$$



根据之前在计算线性高斯模型时，使用的定理可以得到
$$
x^*w \sim N(x^*\mu_w,x^{*T}\Sigma_wx^*)
$$


##### 计算$y$

上述 $f(x^*)$ 可以被视为无噪声的预测值，加上噪声之后，因为噪声服从均值为 0，方差为 $\delta^2$ 的高斯分布，所以噪声对新分布的均值并无影响，而对方差有影响


$$
y = f(x^* ) + \epsilon ~;~~\epsilon \sim N(0,\delta^2) \\
\space \\
y \sim N(x^*\mu_w,x^{*T}\Sigma_wx^* + \delta^2)
$$




## 有偏估计与无偏估计

假设在 **2 维**的情况下，对 $\theta$ 进行 MLE 估计，得到 $\theta_{MLE}$ 如下


$$
\mu_{MLE} = \frac{1}{N} \sum _{i=1} ^N x_i \\\delta_{MLE}^2 = \frac{1}{N} \sum _{i=1} ^N (x_i - \mu_{MLE})^2
$$
$\delta_{MLE}$ 的估计值为**有偏估计**，对$\delta_{MLE}$ 求期望如下
$$
E[\delta_{MLE}] = E[\underbrace{\frac{1}{N} \sum _{i=1} ^N (x_i - \mu_{MLE})^2}] \tag{1}
$$
对上述括号内的式子，提出来并进行简化


$$
\frac{1}{N} \sum _{i=1} ^N (x_i - \mu_{MLE})^2 = \frac{1}{N} \sum _{i=1} (x_i^2 - 2x_i\mu_{MLE} + \mu_{MLE}^2) \\\space 将 x_i 与 \mu_{MLE} 的关系带入 \\= \frac{1}{N} \sum _{i=1} ^N x_i^2 - 2\mu_{MLE}\sum _{i=1} ^N x_i + N\mu_{MLE}^2 \\= \frac{1}{N} \sum _{i=1} ^N x_i^2 - 2\mu_{MLE} \times N\mu_{MLE} + N\mu_{MLE}^2 \\= \frac{1}{N} \sum _{i=1} ^N x_i^2 - 2N\mu_{MLE}^2 + N\mu_{MLE}^2 \\= \frac{1}{N} \sum _{i=1} ^N x_i^2 - N\mu_{MLE}^2 \\= \frac{1}{N} \sum _{i=1} ^N x_i^2 - \mu_{MLE}^2\tag{2}
$$
重写 (1) 式可以得到
$$
E[\delta_{MLE}] =  E[\frac{1}{N}\sum _{i=1} ^N x_i^2 - \mu_{MLE}^2 \tag{2}] \\\space 添加一个 \mu^2 减去一个 \mu^2\\=   E[\frac{1}{N}(\sum _{i=1} ^N x_i^2 - \mu^2) - (\mu_{MLE}^2 - \mu^2)] \\= E[\frac{1}{N} \sum _{i=1} ^N (x_i^2 - \mu^2)] -  E[ (\mu_{MLE}^2 - \mu^2)] \\= \frac{1}{N} \sum _{i=1} ^NE[x_i^2 - \mu^2] - (E[\mu_{MLE}^2] - E[\mu^2)]) \\= \frac{1}{N} N Var(x_i) - (E[\mu_{MLE}^2] - \underbrace{\mu^2}_{E[\mu_{MLE}]^2}) \\= Var(x_i)  - Var(\mu_{MLE}) \\= \delta^2 - Var[ \frac{1}{N} \sum _{i=1} ^N x_i] = \delta^2 -  \frac{1}{N^2} \sum _{i=1} ^N Var(x_i) \\= \delta^2 - \frac{1}{N^2}N \delta^2 = \delta^2 - \frac{1}{N} \delta^2 = \frac{N-1}{N}\delta^2
$$
从而可知，通过 MLE 对 $\delta^2$ 的估计为有偏估计，所以需要消除其有偏性，也就是使得


$$
\frac{N}{N-1}E[\delta_{MLE}^2] =\frac{N}{N-1} E[\frac{1}{N} \sum _{i=1} ^N (x_i - \mu_{MLE})^2] \\= \frac{1}{N-1}E[ \sum _{i=1} ^N (x_i - \mu_{MLE})^2]
$$
