---
layout:     post   				    # 使用的布局（不需要改）
title:      PGM 基础 				# 标题 
subtitle:   PGM          #副标题
date:       2019-05-10 				# 时间
author:     WYX 						# 作者
header-img: img/3.3.png 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - VI,PGM

---



# PGM 基础

本文遵循b站 “机器学习-白板推导系列（九）-概率图模型”

## 背景

![](https://ae01.alicdn.com/kf/HTB1iW3jVxTpK1RjSZFMq6zG_VXaH.jpg)

- 链式法则对任何的分布都成立

### 条件概率表格以及联合概率表格的不同

注意区分条件概率表格以及联合概率表格的区别。 主要在于样本空间的不同

条件概率表格如下所示，每一行相加概率值为 1，以P($s|i$) 举例，其样本空间为P(i)

![](https://ae01.alicdn.com/kf/HTB1rQXJXR1D3KVjSZFyq6zuFpXaE.jpg)



联合概率如下，整个表格相加概率值为 1，因为其样本空间为 P（X,Y）

![](https://ae01.alicdn.com/kf/HTB15INIXLWG3KVjSZFPq6xaiXXaX.jpg)



## 为什么后验概率难求

在概率图模型中遇到的问题在于参数太多，超出计算机储存能力

比如，链式法则对于任何概率图模型均成立，如下所示，假设存在一个 K 维的随机变量，每个随机变量均为 Binary


$$
X = [X_1,X_2,X_3,\ldots,X_K] ^T
$$


则对于其联合概率 P($x_1,x_2,x_3,\ldots,x_K$)，可以利用链式法则写为


$$
P(X) = p(x_1)P(x_2|x_1)P(x_3|x_1,x_2)\ldots P(x_K|x_1,\ldots,x_{K-1})
$$


因为变量之间互不独立，则**建立一个 K 维的联合概率的表格**对其进行描述，**参考上一节 P(X,Y) 的联合概率表格**

其中联合概率 $P(X) = 1$

每一个概率值为一个参数，则在上述表格中每一个变量存在 2 种不同的值，一共存在 K 个不同的变量，则一共存在 $2^K$ 个值，假设存在 100 个变量，则参数值达到 $2^{100}$



### 为什么假设条件独立，会降低所需的参数量

假设存在 4 个二值变量，使用链式法，因为变量之间互不独立，所以只能建立与上表类似的一个联合概率分布表，其参数值为 $2^4 - 1$ （-1，是因为只剩下最后一个概率时不需要求）

如果存在以下假设


$$
P(x_2|x_1,x_3) = P(x_2|x_1) \\
\space \\
P(x_3|x_1,x_2) P(x_3|x_1)\\
\space \\
P(x_4|x_1,x_2,x_3) = P(x_4|x_2,x_3)
$$


则联合概率P(X) 可以表示为 


$$
P(X) = P(x_1)P(x_2|x_1)P(x_3|x_1)P(x_4|x_2,x_3)
$$


对上述联合概率，可以建立 4 个**条件概率表格**来表示这 4 个条件概率，则其参数个数可由加法进行表示


$$
参数个数 = 1 + 2 + 2 + 4 = 9
$$


以下为 $P(x_1)$ 的概率表

| $x_1$ = 1  |  $x_1 = 0$  |
| :--------: | :---------: |
| 0.3 (para) | 0.7(1-para) |

概率表 $P(x_2|x_1)$ 可以表示为，**每一行的加和为 1**

，一共有 2 个参数（因为每行加和为1）

|            | $x_2 =  0$ | $x_2 = 1$     |
| ---------- | ---------- | ------------- |
| $x_1 = 0 $ | parameter1 | 1 - parameter |
| $x_1 = 1$  | para2      | 1 - para2     |



概率表$P(x_4|x_2,x_3)$ 可以表示为

一共存在 4 个参数

|                   | $x_4 = 1$ | $x_4 = 0$ |
| ----------------- | --------- | --------- |
| $x_2 = 0,x_3 = 0$ | para1     | 1 - para1 |
| $x_2 = 0,x_3 = 1$ | para2     | 1 - para2 |
| $x_2 = 1,x_3 = 0$ | para3     | 1 - para3 |
| $x_2 = 1,x_3 = 1$ | para4     | 1 - para4 |



Note：

对于链式法则，也可以使用 K 个条件概率表格对其进行描述，但是参数量是一样的，对于最后一个$P(x_K|x_1,\ldots,x_{K-1})$ 需要$2^{k-1}$ 个参数，根据等差数列，一共有


$$
\underbrace{1 + 2 + 2^2 + \ldots + 2^{K-1}}_{K \ terms} = 1 + \frac{(K-1)(2 + 2^{K-1})}{2}
$$








在概率图模型中的贝叶斯网络以及无向图中，两种图分别能表示一些对方图无法表示的分布

![1557908514210](https://ae01.alicdn.com/kf/HTB1A3dBXQ5E3KVjSZFCq6zuzXXaX.jpg)







## 贝叶斯网络(有向图)

  ![](https://ae01.alicdn.com/kf/HTB1o2.rVrrpK1RjSZTEq6AWAVXae.jpg)

### 条件独立性


$$
X_A \perp X_C|X_B
$$
表示在给定 $X_B$ 集合的情况下，$X_A$ 以及$X_C$ 相互独立

### 因子分解

因子分解是对链式法则的简化


$$
P(X_1,X_2,\ldots,X_p) = \prod_{i=1}^P P(X_i|X_{pals}), 其中\space pals \space 表示X_i 节点的所有父亲节点
$$

### 三种结构(局部特点)

三种结构代表不同的规律，结构的规律都是总结出来的，并不是凭空猜想的。复杂的贝叶斯网络由这三种结构构成

![](https://ae01.alicdn.com/kf/HTB1B6.vVwHqK1RjSZFgq6y7JXXaZ.jpg)

#### 倒 V 结构

**也称为 tail to hail 结构**


$$
tail \rarr head
$$
在概率图中，箭头起点被称为 tail，右端终点被称为 head

在倒 V 结构中，从 a 的角度来看，a 分别是两个节点 b 和 c 的tail， 因此被称为 tail 结构

##### 条件独立性

代表 $c \perp b | a$ , 代表在默认情况下，路径连通，也就是说 b 与 c 不独立，若 a 被观测，则 b 与 c 之间路径堵塞（也就是独立）

- 理解为亲属关系，b,c 为 a 的两个孩子，如果 a 出了情况，则 b 与 c 无联系

根据链式法则进行推导:
$$
链式法则 \Rightarrow P(a,b,c) = P(a) P(b|a) P(c|a,b) \\
\space 
\\
概率图 \Rightarrow P(a,b,c) = P(a) P(b|a) P(c|a) \\
\space 
\\
综合链式法则以及概率图，可以得到:\\
\space
\\
\Rightarrow p(c|a,b) = P(c|a) \\
\space 同时乘上 P(b|a)
\\
\Rightarrow \underbrace{P(c|a,b)P(b|a)}_{P(b,c|a)} = P(c|a) P(b|a)
$$


### Head to tail 结构 （顺联结构）

从 b 的视角来看，b 分别是节点 a 的 head 以及 c 的tail，所以被称为 head to tail 结构

在给定 b 的情况下，a 与 c 独立，以条件独立性来说，也就是


$$
a \perp c |b
$$


若 b 被观测到，则 a 到 c 的路径被阻塞，也就是说 给定 b，a 与 c 独立

- 解释为爷爷 -> 父亲 -> 儿子的关系，一旦父亲被观测到，则爷爷与儿子，关系断裂

#### Head to Head 结构 （V 型结构）

被称为 V 型结构，从 c 的角度来看，c 分别是 a 和 b 的head，因此被称为是head to head 结构

**在默认情况下，V 型结构自身为独立的**

在给定 c 的情况下，**a 与 b 反而不独立**

- 解释为父亲与母亲以及孩子之间的关系，没有孩子之前，父亲与母亲独立，有了孩子，父亲与母亲不独立

**根据链式法则以及概率图推导上述关系**


$$
链式法则 \Rightarrow P(a,b,c) = P(a) P(b|a) P(c|a,b) \\
\space 
\\
概率图 \Rightarrow P(a,b,c) = P(a) P(b) P(c|a,b) \\
\space 
\\
综合链式法则以及概率图，可以得到:\\
\space
\\
\Rightarrow P(b|a) = P(b)，表示 \space a \space 与 \space b \space 独立
$$


当，b 有了孩子的时候，当孩子被观测到时，路径仍然连通，也就是 a 与 c 仍然不独立





### D-Separation (D 划分)

![](https://ae01.alicdn.com/kf/HTB1NF3FVpzqK1RjSZFoq6zfcXXaq.jpg)

D 划分对于条件独立性总结了 2 条规则，其中 V 结构自身构成一条规则，顺联以及倒 V 性质构成一条规则

条件独立性即为 ： $ X_A \perp X_C | X_B$ , 其中 $X_A,X_B,X_C$ 均为节点的集合。

- 如果集合 $X_A \perp X_C$ （也就是互相独立），**如果其节点构成满足倒 V 结构或者顺联结构**，则其中 b 节点一定属于 $X_B$
- 如果集合 $X_A \perp X_C$ ，**如果其节点满足 V 型结构**，则其中 b 节点一定**不属于** $X_B$ ，否则 $a\in X_A$ 以及 $c \in X_C$ 互相连通(回忆，在 V 型结构中，默认状态下， a 与 c 互相独立)

上述两条对于条件独立  性的规则的叙述，被称为**全局 Markov Property**

#### Markov Blanket 马尔科夫毯

马尔科夫毯叙述了当前节点与全部变量的关系，仅取决于当前节点与

- 其父亲，母亲（可能有数个）
- 其孩子（可能有数个）
- 其配偶（可能有数个）

的关系，与除此之外其他所有的节点均无关系

### 贝叶斯网络模型

![](https://ae01.alicdn.com/kf/HTB1OSM_VAPoK1RjSZKbq6x1IXXaL.jpg)





## 马尔科夫随机场 Markov Network （无向图）

![](https://ae01.alicdn.com/kf/HTB1ejU_VpzqK1RjSZFoq6zfcXXaA.jpg)

马尔科夫无向图网络的条件独立性：

- 无向图中间因为不存在方向性，则只需要考虑贝叶斯网络中 **D 分离的第一种情况**
  - 在 给定 $ X_B$ 集合的时候，$X_A$ 与 $X_C$ 集合独立
  - 意思如果 $a\in X_A$ 以及 $b \in X_C$ 之间存在若干个节点，则必然有一个节点属于 $X_B$  

- 当前节点除了与有边存在的节点不独立之外，与其他所有的节点都在给定邻居的情况下独立

$$
a \perp \lbrace全集 - a - a 的邻居\rbrace | a 的邻居
$$

- 所谓成对 Markov 网络即为，$X_i$ 与 $X_j$ 之间无边连接，在全集中减去 i 和 j，则 $X_i$ 与 $X_j$ 独立

$$
X_i \perp X_j | X_{-i-j}
$$

#### 势能函数 Potential Function

在无向图中，势能函数代表了某种能量，可以自己进行定义。无向图的条件独立性由图中的最大团进行定义，为最大团势能函数的乘积，其中 $Z$ 代表归一化因子，确定联合概率为 1

![](https://ae01.alicdn.com/kf/HTB1YQtIV4YaK1RjSZFnq6y80pXaE.jpg)

**势函数可以表示任意概率，条件概率或是联合概率**

以下述图像为例，说明势函数

![](https://ae01.alicdn.com/kf/HTB13Y0VV4naK1RjSZFtq6zC2VXaR.jpg)



X与Y构成一个最大团（clique），假设 X 与 Y 均为 binary



|  X   |  Y   | Potential Function |
| :--: | :--: | :----------------: |
|  0   |  0   |         10         |
|  0   |  1   |         0          |
|  1   |  0   |         5          |
|  0   |  0   |         5          |



**势函数就是自己定义的函数，当变量具有某种分布时，呈现出较大的能量。但是势函数一定要大于 0 ，因为要保证在无向图的条件独立性乘积中，使得概率为正数**



## 推断

### 变量消去



### 信念传播（sum-product）

![](https://ae01.alicdn.com/kf/HTB14_LpVNjaK1RjSZFAq6zdLFXag.jpg)

在信念传播中，就是应用变量消除的思想，加上记录数值，得到信念传播，其中


$$
m_{j \rightarrow i}(X_i) = \sum_{X_j} \varphi_j \varphi_{X_j,X_i} \prod_{k\in NB(j)-i} m_{k \rightarrow j(X_j)} \\
\space 
\\
NB \space 表示其邻居
$$




$m_{j \rightarrow i}(X_i)$ 表示从节点 j 传入节点 i时，加和消去所有与 j 有关的概率，只剩下与 i 有关的概率(类似 HMM 的前向性算法)。这里表示路径

$P(X_i)$ 表示节点的概率。 $P(X_i) = \varphi_i(X_i) \prod_{k \in NB(i)} m_{k \rightarrow i} (X_i)$  ，其中 $\varphi_i(X_i)$ 表示节点 i 自身的势能函数   



具体传播见下图，i, j 分别代表节点



![](https://ae01.alicdn.com/kf/HTB1g.fFVSzqK1RjSZPxq6A4tVXa6.jpg)



![](https://ae01.alicdn.com/kf/HTB1wpDJVH2pK1RjSZFsq6yNlXXaI.jpg)



  ### Max-Product



相较于 **sum-product** 消去当前变量的所有可能值，**max-product** 每次进行传播的时候，取路径的一个最大值

![](https://ae01.alicdn.com/kf/HTB1KqvPVG6qK1RjSZFmq6x0PFXai.jpg)





### 道德图 Moral Graph

将有向图转化为无向图

回忆在贝叶斯网络中，一共有三种局部结构：

- V 结构
- 倒 V 结构
- 顺联结构

其中顺联结构以及倒 V 结构在转化为其道德图时，只需要取出箭头即可

以下图笔记，右上方倒 V 结构进行举例


$$
P(a,b,c) = \underbrace{P(a)P(b|a)}_{\phi (a,b)}\underbrace{P(c|a)}_{\phi (a,c)}
$$


**在进行因子分解之后，将所有包含同一种变量的式子分为一类，可以画出其团，其中$\phi (a,b)$ 表示其势能函数**

![](https://ae01.alicdn.com/kf/HTB1RXt_XACy2eVjSZSyq6xukVXaF.jpg)



在进行 V 结构的转换时，需要注意


$$
P(a,b,c) = \underbrace{P(a)P(b)P(c|a,b)}_{\phi(a,b,c)}
$$


c 元素同时取决于两个变量，无法完全分离，只能添加线使 abc 成为一个团

- 在 V 结构存在多个父母的情况下，将父母之间两两连线





### I-Map

假设存在一个分布 **P**, 如果图 **G** 所有的独立性均同样存在在 **P** 中，则称 **G** 为 **P** 的**I-Map**

如果假设 **I(P)** 为 **P** 中一系列形如 $(X \perp Y|Z)$ 的独立性假设。同样地，设 **I(K)** 为图 **K** 中独立性假设集合，若存在关系


$$
I(K) \in I(P)
$$


则说 **K** 为 **P** 的 **I-Map**  









# Reference

[机器学习-白板推导系列（九）-概率图模型](<https://www.bilibili.com/video/av33545406/?p=2>)