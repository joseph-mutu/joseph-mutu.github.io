---
layout:     post   				    # 使用的布局（不需要改）
title:      EM 				# 标题 
subtitle:   EM Algo #副标题
date:       2019-04-14 				# 时间
author:     WYX 						# 作者
header-img: img/1.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - PGM,EM
---



# EM 算法

### 离散变量边缘分布

假设二维随机变量(X,Y) 的每个分量均为一维离散随机变量。设{${x_1,x_2,...}$} 和{$y_1,y_2,...$}为X 和 Y 的全部取值，则有


$$
P(X=x_i) = P(X=x_i,Y< \infty) = \sum_{j}P(X=x_i,Y=y_j)
$$



## 似然函数 likelihood function

给定样本集，求解使样本最大化的模型参数 $\theta$, 参数$\theta$ 相对于样本集的似然函数可以表示为:



$$
L(\theta) = logP(X|\theta) \tag{1}
$$



Note: 参数$\theta$ 表示模型的全部参数，是一个参数集合。假设样本全部服从一个正态分布，则$\theta = ( \mu ,\delta)$

若模型含有隐变量 $Z$，上式似然函数(1)可以表示为$X$的边缘分布:



$$
L(\theta) = logP(X|\theta) = \sum_{Z} logP(X,Z|\theta) \tag{2}
$$

由于似然函数有如下形式，所以求解困难



$$
\frac{\partial log(f_1 + f_2+f_3+...+f_n)}{\partial f_1 }   \tag3
$$



### ELBO and KL Divergence


$$
logP(X|\theta) = log P(X,Z|\theta) - log P(Z|X,\theta) 
$$


引入关于隐变量Z的分布


$$
logP(X|\theta) = log\frac{P(X,Z|\theta)}{q(Z)} - log\frac{P(Z|X,\theta)}{q(Z)}
$$


对等式两边同时求 $q(Z)$的积分


$$
left = \int_Z q(Z) logP(X|\theta)dz = logP(X|\theta)\underbrace{\int_Z q(Z) dz}_1
$$

$$
right = \underbrace{\int_Z q(Z) log\frac{P(X,Z|\theta)}{q(Z)} dz}_{ELBO} \underbrace{- \int_Z q(Z)log\frac{P(Z|X,\theta)}{q(Z)} dz}_{KL \space Divergence}
$$


则似然函数可重写为


$$
logP(X|\theta) = ELBO + \mathbb{KL}(q(Z)||P(Z|X,\theta))
$$

$$
log P(X|\theta) \geq ELBO, because \space \mathbb{KL}(q(Z)||P(Z|X,\theta)) \geq 0
$$

$$
log P(X|\theta) = ELBO, when \space \mathbb{KL}(q(Z)||P(Z|X,\theta)) = 0
$$


也就意味着当 $q(Z) = P(Z|X,\theta)​$,


$$
logP(X|\theta) = ELBO
$$


固定  $q(Z) = P(Z|X,\theta)$ 也就是 E-step，接下来要将 ELBO 最大化，即


$$
\theta^{t+1} = \arg\max_\theta \int_Z P(Z|X,\theta^t) log\frac{P(X,Z|\theta)}{P(Z|X,\theta^t)} dz
$$

$$
\theta^{t+1} = \arg\max_\theta \int_Z P(Z|X,\theta^t) logP(X,Z|\theta) dz - \underbrace{\int_Z P(Z|X,\theta^t)P(Z|X,\theta^t) dz}_{constant}
$$


M-step


$$
\theta^{t+1} = \arg\max_\theta \int_Z P(Z|X,\theta^t) logP(X,Z|\theta) dz
$$


注意，在上式中，variables 只有 $\theta$ ,$\theta^t$ 为常量，



## Jensen Inequality

### Jensen 不等式

设 $f(x)$ 为**凸函数**，则有


$$
\mathbb{E}(f(x)) \geq f(\mathbb{E(x)})
$$


在下图中，将 $\lambda$ 视为二项分布的概率分布，则


$$
\mathbb{E}(f(x)) = \lambda f(x_1) +(1-\lambda)f(x_2) \geq f(\lambda x_1 + (1-\lambda)x_2)
$$


若 f(x) 为 concave function，则上述关系反号:


$$
\mathbb{E}(f(x)) \leq f(\mathbb{E(x)})
$$



#### 示例

假设 $\lambda = \frac{1}{2}$, $f(x)$ 为凸函数，则根据 Jensen 不等式，有


$$
f(\underbrace{\frac{x_1}{2} + \frac{x_2}{2}}_{Expextation}) \geq \underbrace{\frac{f(x_1)}{2} + \frac{f(x_2)}{2}}_{Expextation}
$$






![Jesan 不等式](https://pic.superbed.cn/item/5cb43ef53a213b041748aaab)

### Q 函数引入

#### Log 函数凸性

对 $log x$ 求二阶导数，


$$
\frac{\partial^2 logx}{\partial x^2} = - \frac{1}{x^2} \leq 0
$$


则可得 $logx​$ 为 concave 函数

#### 函数的数学期望

设随机变量$X$及其函数$g(X)$ 的数学期望都存在，则有



$$
\begin{equation}
\mathbb{E}[g(X)] = \begin{cases}
\sum_i g(x_i)p(x_i), & 离散场合 \\
\int_{-\infty}^{+\infty} g(x)p(x)dx, & 连续场合
\end{cases}
\end{equation}
$$




* 在离散场合, $p(x_i) 为 x_1,x_2,x_3,... 的分布$
* 在连续场合，$p(x) 为X的概率密度函数​$

---

似然函数 (2) 可以写为
$$
logP(X|\theta) = log\int_Z q(Z) \frac{P(X,Z|\theta)}{q(Z)}dz, q(Z) 为隐变量分布 \tag{4}
$$

$$
\geq log\int_Z q(Z) log \frac{P(X,Z|\theta)}{q(Z)} \tag{5}
$$

$$
= log\mathbb{E}_{q(Z)}log \frac{P(X,Z|\theta)}{q(Z)} \tag{5}
$$

$$
= \underbrace{log\sum_Z q(Z) P(X,Z|\theta)}_{ELBO} - \underbrace{log\sum_Z q(Z)q(Z)}_{constant} \tag{6}
$$


$$
logP(X|\theta) = ELBO, when \space \frac{P(X,Z|\theta)}{q(Z)} = c,
$$

$$
\frac{P(X,Z|\theta)}{q(Z)} = c \tag{7}
$$

$$
\Rightarrow P(X,Z|\theta) = cq(Z)\\
$$

$$
\Rightarrow  \frac{P(X,Z|\theta)}{c} = q(Z)
$$

$$
\Rightarrow \int_{q(Z)} \frac{P(X,Z|\theta)}{c}dz = \underbrace{\int_{q(Z)} q(Z) dz}_1 \\
$$

$$
\Rightarrow \frac{P(X|\theta)}{c} = 1
$$

$$
\Rightarrow c = P(X|\theta) \tag{8}
$$

Take (8) back into (7)
$$
\frac{P(X,Z|\theta)}{q(Z)} = P(X|\theta) \\ 
\Rightarrow \frac{P(Z|X,\theta)P(X|\theta)}{P(X|\theta)} = q(Z) \\
\Rightarrow q(Z) = p(Z|X,\theta)
$$




**Note**:

在(4)式中


$$
\sum_Z q(Z) \frac {P(X,Z|\theta)}{q(Z)}   为期望 \\
$$

$$
\frac{P(X,Z|\theta)}{q(Z)} 为g(Z)
$$


则 


$$
log\sum_Z q(Z) \frac{P(X,Z|\theta)}{q(Z)} = f(\mathbb{E(x)})
$$


根据 log 函数为凹函数这一性质，可以得到


$$
f(\mathbb{E(x)}) =log\sum_Z q(Z) \frac{P(X,Z|\theta)}{q(Z)} \geq log\sum_Z q(Z) log \frac{P(X,Z|\theta)}{q(Z)} = \mathbb{E(f(x))}
$$



# Reference

1. [机器学习-白板推导系列（十）-EM算法（Expectation Maximization）](<https://www.bilibili.com/video/av31906558/?p=3>)
2. [[EM算法及其应用（一）](https://www.cnblogs.com/massquantity/p/9248482.html)](<https://www.cnblogs.com/massquantity/p/9248482.html>)

