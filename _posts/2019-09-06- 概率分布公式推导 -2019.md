---
layout:     post   				    # 使用的布局（不需要改）
title:      概率分布基础公式推导			# 标题 
subtitle:   概率分布 #副标题
date:       2019-09-06 				# 时间
author:     WYX 						# 作者
header-img: img/5.7.jpg	                 #这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - Probability Distributions  
---



<center>
    <img src= "https://github.com/joseph-mutu/Pics/raw/master/%E4%B8%80%E7%BB%B4%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E8%81%94%E7%B3%BB.jpg" width = "800"/>
</center>

# 概率论相关公式推导

## 两个不等式

### 马尔可夫不等式

已知数据特征 `期望` 的情况下，反推**概率累积函数**的情况

已知期望的计算方法如下
$$
E(X) = \sum \limits_{x_i} x_i P(X = x_i)
$$
则，如果要估计 $P(X>a)$ 的情况，有以下成立


$$
P(X \geq a) \leq \frac{E(X)}{a}
$$

### 切比雪夫不等式

已经数据特征`方差`的情况下，反推概率累积函数的情况


$$
P(|X-\mu| \geq k) \leq \frac{\sigma^{2}}{k^{2}}
$$


以下图为例进行解释

$P(|X-\mu| > k)$ 即随机变量距离 `期望` 的距离大于 k 的可能性，在`方差` $\delta^2$ 不变的情况下，随着 k 的增大，则 $\frac{\delta^2}{k^2}$ 也在不断增大

则上述切比雪夫不等式表示，随机变量 X 会大概率围绕在 期望$\mu$ 附近

<center>  
    <img src = 'https://github.com/joseph-mutu/Pics/raw/master/%E6%A6%82%E7%8E%87/%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F.jpg' width = "500"/>
</center>



### 大数定理

<center>
    <img src = "https://github.com/joseph-mutu/Pics/raw/master/%E6%A6%82%E7%8E%87/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B.jpg" width = "500"/>
</center>



#### 伯努利大数定律

伯努利大数定律描述，在 n 次独立的伯努利试验中（**要求随机变量服从 Bernolli 分布**），随着试验次数的增加，事件 A 发生的频率 $\frac{N_A}{N}$ 无限接近概率 P

<center>
    <img src = "https://github.com/joseph-mutu/Pics/raw/master/%E6%A6%82%E7%8E%87/Bernolli%20Big%20Number.jpg" width = "600"/>
</center>



#### 辛钦大数定律

辛钦大数定理对随机变量**不要求**一定服从 `Bernolli 分布`，但是要求随机变量服从分布，并具有相同的期望

令
$$
\bar{X} = \frac{X_1 + X_2 + \ldots + X_N}{N}
$$


<center>
    <img src = "https://github.com/joseph-mutu/Pics/raw/master/%E6%A6%82%E7%8E%87/%E8%BE%9B%E9%92%A6%E5%A4%A7%E6%95%B0.jpg" width = "600"/>
</center>

辛钦大数描述，随着抽样样本数目的增加，则**样本的算术平均**则接近其共同的数学期望

#### 切比雪夫大数定律

切比雪夫大数定理**不要求**随机变量服从同一分布，但要求各个随机变量 $X_i$ 的方差存在，且有共同上界，即


$$
Var(X_i) \leq c, i = 1,2,\ldots,n
$$


取 $\bar{X}$ 为随机变量的平均，令 $\mu = E(\bar{X})$


$$
\bar{X} = \frac{X_1 + X_2 + \ldots + X_N}{N}
$$

<center>
    <img src = "https://github.com/joseph-mutu/Pics/raw/master/%E6%A6%82%E7%8E%87/%E8%BE%9B%E9%92%A6%E5%A4%A7%E6%95%B0.jpg" width = "600"/>
</center>





### 样本与总体

#### 样本方差与总体方差之间的关系

##### 样本方差

设 $X_1,X_2,\ldots X_n$ 为 取自总体中的样本，则


$$
S^2 = \frac{1}{n-1} \sum \limits_{i=1}^N (X_i - \bar{X})^2 \tag{1}
$$
为样本方差，(1) 也可以简化为 (2)


$$
S^2 = \frac{1}{n-1}  \sum \limits_{i=1}^N (X_i^2 - 2*X_i\bar{X} + \bar{X}^2) \\
 =  \frac{1}{n-1}  (\sum \limits_{i=1}^N X_i^2 - 2\sum \limits_{i=1}^N X_i \bar{X} + n\bar{X}^2) \\
\space \\
由~ \bar{X} = \frac{X_1 + X_2 + \ldots + X_N}{n} \rightarrow \sum \limits_{i=1}^N X_i = n\bar{X} \\
\space \\
 =\frac{1}{n-1}  (\sum \limits_{i=1}^N X_i^2 - 2 n\bar{X}^2 + n\bar{X}^2) \\
 = \frac{1}{n-1}  (\sum \limits_{i=1}^N X_i^2 - n\bar{X}^2 ) \tag{2}
$$

#### 样本方差与总体方差的关系

样本方差与总体方差有如下关系


$$
E(S^2) = \delta^2
$$
对 (2) 式进行求期望


$$
E(\frac{1}{n-1}  (\sum \limits_{i=1}^N X_i^2 - n\bar{X}^2 )) \\
\space \\
= \frac{1}{n-1} (E(\sum \limits_{i=1}^N X_i^2) - n E(\bar{X^2})) \\
\space \\
= \frac{1}{n-1} (\sum \limits_{i=1}^N E( X_i^2) - n E(\bar{X^2}))
$$


方差的简化计算可得
$$
Var(X) = E(X^2) - E(x)^2 \\
\space \\
= E(X^2) - \mu^2 \\
\space \\
\Rightarrow E(X^2) = \delta^2 + \mu^2
$$





## 分布

#### 几何分布 p(X>m)

抛骰子连抛 m 把也没有 6 点
$$
\begin{equation}
P(X>m)=\underbrace{\sum_{k=m+1}^{\infty}(1-p)^{k-1} p}=\underbrace{\frac{p(1-p)^{m}}{1-(1-p)} }=(1-p)^{m}
\end{equation}
$$

$$
\sum_{k=m+1}^{\infty}(1-p)^{k-1}p \Rightarrow p \sum_{k=m+1}^{\infty}(1-p)^{k-1} \\
\space \\
\Rightarrow p(1-p)^{m} \sum \limits_{k=1}^{\infty} (1-p)^k \\
\space \\
\Rightarrow p(1-p)^{m} {\frac{1}{1-(1-p)}}  = \frac{p(1-p)^{m}}{1-(1-p)}
$$

#### 二项分布的期望计算

利用了二项式定理的反用

##### 二项式定理

$$
(a+b)^n = \sum \limits_{k=0}^n C_{n}^k a^k b^{n-k} \\\space \\=  C_{n}^0 a^0 b^{n} +C_{n}^1 a^1 b^{n-1} + C_{n}^2 a^2 b^{n-2} + \ldots + C_{n}^n a^n b^{0}
$$

##### 期望计算

$$
E(X) = \sum_{x=0}^n x \cdot C_n^x p^{x} (1-p)^{n-x}
$$

目的是利用上式的二项式定理，实现从右到左的简化, 但是上式因为每个 $p^x (1-p)^{n-x}$ 都有不同的系数 x，先将 x 统一化

- 首先注意一点

$$
k C_{n}^k = k \frac{n!}{k!(n-k)!} = \frac{n!}{(k-1)!(n-k)!} = n \cdot \frac{(n-1)!}{(k-1)!(n-k)!} = n  C_{n-1}^{k-1} \tag{1}
$$

- 将 E(X) 展开，注意到第一项为 0，所以将第一项去除


$$
E(X) = \underbrace{0 \cdot C_n^0 p^0 (1-p)^n + 1}_0 \cdot C_n^1 p (1-p)^{n-1} + \ldots \\\space \\E(X) = \sum \limits_{x=1}^n x \cdot C_n^x p^{x} (1-p)^{n-x} \tag{2}
$$

- 利用 (1) 式，将 (2) 化简

$$
E(X) = n \sum \limits_{x=1}^n C_{n-1}^{x-1} p^x (1-p)^{n-x}
$$

- 将每一项提取出一个 p 得到

$$
E(X) = np \sum \limits_{x=1}^n C_{n-1}^{x-1} p^{x-1} (1-p)^{n-x}
$$

如今上式，x 从 x = 1 处开始，**将 x = x+1，则循环从 x = 0出开始进行**

- E(X) 如下

$$
E(X) = np \underbrace{\sum \limits_{x=0}^n C_{n-1}^{x} p^{x} (1-p)^{n-x-1}}_{((1-p)+p)^{n-1}} \\\space \\ = np (1-p+p)^{n-1} = nE(X) = np \underbrace{\sum \limits_{x=0}^n C_{n-1}^{x} p^{x} (1-p)^{n-x-1}}_{((1-p)+p)^{n-1}} \\\space \\ = np (1-p+p)^{n-1} = np
$$



